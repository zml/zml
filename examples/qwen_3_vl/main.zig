const std = @import("std");
const async = @import("async");
const zml = @import("zml");
const qwen = @import("qwen_3_vl.zig");
const clap = @import("clap");
const stdx = @import("stdx");
const floats = zml.floats;

const log = std.log.scoped(.qwen);

test {
    std.testing.refAllDecls(@This());
}

pub const std_options: std.Options = .{
    .log_level = .info,
    .logFn = async.logFn(std.log.defaultLog),
};

const params = clap.parseParamsComptime(
    \\--help                      print this help
    \\--prompt         <STRING>   the prompt
    \\--image          <STRING>   path to the image file (BMP format)
    \\--hf-model-path  <STRING>   path to the directory containing model weights, config and tokenizer
    \\--activations    <STRING>   path to the activations .pt file (unused, kept for compatibility)
    \\--seed           <UINT>     random seed (optional)
    \\--seq-len        <UINT>     sequence length (default: 512)
    \\--create-options <STRING>   platform creation options JSON, defaults to {}
);

pub fn generateText(
    config: qwen.Qwen.Config,
    _: qwen.Qwen3VL,
    mod_prefill: zml.ModuleExe(qwen.Qwen3VL.forward),
    mod_decode: zml.ModuleExe(qwen.Qwen3VL.forward_decode),
    kv_cache_: zml.Bufferized(qwen.KvCache),
    tokenizer: zml.tokenizer.Tokenizer,
    allocator: std.mem.Allocator,
    prompt: []const u8,
    image_path: []const u8,
    preprocessor_config: PreprocessorConfig,
    max_seq_len: u32,
    writer: *std.Io.Writer,
) !void {
    // Preprocess image and prompt
    const preprocessor_input = try preprocessor(
        allocator,
        tokenizer,
        prompt,
        config,
        preprocessor_config,
        image_path,
        max_seq_len,
        1024, // max_side
    );
    defer {
        preprocessor_input.image_buffer_chw.deinit(allocator);
        preprocessor_input.prompt_tokens.deinit(allocator);
        preprocessor_input.prompt_shape.deinit(allocator);
        preprocessor_input.image_dim.deinit(allocator);
        preprocessor_input.token_index.deinit(allocator);
    }

    const platform = mod_decode.platform();
    var tokenizer_decoder = try tokenizer.decoder();
    defer tokenizer_decoder.deinit();

    // Extract prompt_shape values before converting to device buffer
    const prompt_shape_values = preprocessor_input.prompt_shape.items(i32);
    const text_before_image = @as(u32, @intCast(prompt_shape_values[0]));
    const num_image_tokens = @as(u32, @intCast(prompt_shape_values[1]));
    const text_after_image = @as(u32, @intCast(prompt_shape_values[2]));
    log.info("text_before_image: {d}", .{text_before_image});
    log.info("num_image_tokens: {d}", .{num_image_tokens});
    log.info("text_after_image: {d}", .{text_after_image});
    const total_seq_len = text_before_image + num_image_tokens + text_after_image;

    // Prepare device buffers for prefill
    const image_buffer_chw = try preprocessor_input.image_buffer_chw.toDevice(platform);
    defer image_buffer_chw.deinit();

    const prompt_tokens = try preprocessor_input.prompt_tokens.toDevice(platform);
    defer prompt_tokens.deinit();

    const prompt_shape = try preprocessor_input.prompt_shape.toDevice(platform);
    defer prompt_shape.deinit();

    const image_dim = try preprocessor_input.image_dim.toDevice(platform);
    defer image_dim.deinit();

    const token_index = try preprocessor_input.token_index.toDevice(platform);
    defer token_index.deinit();

    // Create a dummy pixel_value_mock for prefill (will be replaced by actual processing)
    const pixel_value_mock_shape = zml.Shape.init(.{ .a = 1, .b = 1 }, .f32);
    const pixel_value_mock = try zml.Buffer.uninitialized(platform, pixel_value_mock_shape, .{});
    defer pixel_value_mock.deinit();

    // init buffers
    var generated_token_buffer = [_]u32{undefined};

    // Prefill: process the full prompt with image
    var kv_cache, var mrope_position_deltas = prefill: {
        const next_token, const next_position, const kv_cache, const mrope_deltas = mod_prefill.call(.{
            image_buffer_chw,
            prompt_tokens,
            image_dim,
            token_index,
            prompt_shape,
            kv_cache_,

            pixel_value_mock,
        });
        _ = next_position;

        // Extract the generated token
        _ = try next_token.toHost(std.mem.sliceAsBytes(&generated_token_buffer));

        break :prefill .{ kv_cache, mrope_deltas };
    };
    defer zml.aio.unloadBuffers(&kv_cache);
    defer mrope_position_deltas.deinit();

    // Prepare for token-by-token generation,
    // start with the token generated based on the full prompt.
    var current_token = try zml.Buffer.fromSlice(platform, .{ .bs = 1, .seq = 1 }, &generated_token_buffer);
    defer current_token.deinit();

    const output_tokens_len = max_seq_len - total_seq_len - 1;
    const start = std.time.microTimestamp();

    // One token has already been generated by the prefill.
    var num_tokens_generated: usize = 1;

    // Store all generated tokens
    var generated_tokens = try std.ArrayList(u32).initCapacity(allocator, output_tokens_len);
    defer generated_tokens.deinit(allocator);

    // Store the first token from prefill
    //try generated_tokens.append(allocator, generated_token_buffer[0]);
    const token_gen = max_seq_len - total_seq_len - 1;
    generation: for (0..token_gen) |i| {
        // collect and print generated sequence
        num_tokens_generated += 1;
        const generated_token = generated_token_buffer[0];
        try generated_tokens.append(allocator, generated_token);
        if (try tokenizer_decoder.next(generated_token)) |chunk| {
            try writer.writeAll(chunk);
        }

        // check for eos
        if (i == output_tokens_len) break :generation;
        if (generated_token == 151643 or generated_token == 151645) break :generation;

        // current token pos needs to go into a zml.Buffer
        const cache_position_buffer = &[_]i64{@intCast(total_seq_len + i)};
        log.info("total_seq_len: {d}", .{total_seq_len});
        const cache_position = try zml.Buffer.fromSlice(platform, .{}, cache_position_buffer);
        defer cache_position.deinit();

        // call to generate the next token
        const next_token, const next_position, const updated_kv_cache, const updated_mrope = mod_decode.call(.{ current_token, cache_position, kv_cache, mrope_position_deltas });
        _ = next_position;

        current_token = next_token;
        kv_cache = updated_kv_cache;
        mrope_position_deltas = updated_mrope;

        // extract the generated token from the buffer
        _ = try current_token.toHost(std.mem.sliceAsBytes(&generated_token_buffer));
    }

    const end = std.time.microTimestamp();
    const duration = stdx.math.divFloat(f64, end - start, std.time.us_per_s);
    const speed = @as(f64, @floatFromInt(num_tokens_generated)) / duration;

    // Decode and print all generated tokens at the end
    std.debug.print("\n", .{});
    for (generated_tokens.items) |token| {
        if (try tokenizer_decoder.next(token)) |chunk| {
            try writer.writeAll(chunk);
        }
    }

    std.debug.print("\n", .{});
    log.info("✅ Generated {d} tokens in {:.3}s: {d:.3}tok/s", .{ num_tokens_generated, duration, speed });
}

pub fn main() !void {
    try async.AsyncThread.main(std.heap.c_allocator, asyncMain);
}

pub fn asyncMain() !void {
    log.info("   Qwen3-VL was compiled with {}", .{@import("builtin").mode});

    const allocator = std.heap.c_allocator;

    const parsers = comptime .{
        .BOOL = bool_parser,
        .UINT = clap.parsers.int(u32, 0),
        .STRING = clap.parsers.string,
        .PATH = clap.parsers.string,
    };
    var diag: clap.Diagnostic = .{};
    var stderr_buffer: [1024]u8 = undefined;
    var stderr = std.fs.File.stderr().writer(&stderr_buffer);
    defer stderr.interface.flush() catch {};

    var cli = clap.parse(clap.Help, &params, parsers, .{
        .diagnostic = &diag,
        .allocator = allocator,
    }) catch |err| {
        diag.report(&stderr.interface, err) catch {};
        stderr.interface.writeAll("usage: ") catch {};
        clap.usage(&stderr.interface, clap.Help, &params) catch {};
        stderr.interface.writeAll("\n") catch {};
        return;
    };
    defer cli.deinit();

    if (cli.args.help != 0) {
        clap.help(&stderr.interface, clap.Help, &params, .{}) catch {};
        return;
    }

    const hf_model_path = cli.args.@"hf-model-path" orelse {
        log.err("Missing --hf-model-path", .{});
        return;
    };

    const image_path = cli.args.image orelse {
        log.err("Missing --image", .{});
        return;
    };

    // Handle activations argument (unused, kept for compatibility)
    _ = cli.args.activations;

    const model_config_path = try std.fs.path.join(allocator, &.{ hf_model_path, "config.json" });
    defer allocator.free(model_config_path);

    const model_weights_path = b: {
        const simple_path = try std.fs.path.join(allocator, &.{ hf_model_path, "model.safetensors" });
        if (async.File.access(simple_path, .{})) {
            break :b simple_path;
        } else |_| {
            allocator.free(simple_path);
        }

        const sharded_path = try std.fs.path.join(allocator, &.{ hf_model_path, "model.safetensors.index.json" });
        break :b sharded_path;
    };
    defer allocator.free(model_weights_path);

    const model_tokenizer_path = try std.fs.path.join(allocator, &.{ hf_model_path, "tokenizer.json" });
    defer allocator.free(model_tokenizer_path);

    const preprocessor_config_path = try std.fs.path.join(allocator, &.{ hf_model_path, "preprocessor_config.json" });
    defer allocator.free(preprocessor_config_path);

    // Load config
    const config = blk: {
        var config_json_file = try async.File.open(model_config_path, .{ .mode = .read_only });
        defer config_json_file.close() catch unreachable;
        var config_json_buffer: [256]u8 = undefined;
        var config_reader = config_json_file.reader(&config_json_buffer);
        var reader = std.json.Reader.init(allocator, &config_reader.interface);
        defer reader.deinit();
        const config_obj = try std.json.parseFromTokenSourceLeaky(qwen.Qwen.Config, allocator, &reader, .{ .ignore_unknown_fields = true });
        break :blk config_obj;
    };

    // Load preprocessor config
    const preprocessor_config = blk: {
        var preprocessor_config_json_file = try async.File.open(preprocessor_config_path, .{ .mode = .read_only });
        defer preprocessor_config_json_file.close() catch unreachable;
        var preprocessor_config_json_buffer: [256]u8 = undefined;
        var preprocessor_config_reader = preprocessor_config_json_file.reader(&preprocessor_config_json_buffer);
        var reader = std.json.Reader.init(allocator, &preprocessor_config_reader.interface);
        defer reader.deinit();
        const preprocessor_config_obj = try std.json.parseFromTokenSourceLeaky(PreprocessorConfig, allocator, &reader, .{ .ignore_unknown_fields = true });
        break :blk preprocessor_config_obj;
    };

    var context = try zml.Context.init();
    defer context.deinit();

    const compilation_options = zml.CompilationOptions{
        .xla_dump_to = "/tmp/zml/qwen3vl",
        .sharding_enabled = true,
    };

    // Initialize ZML platform
    const create_opts_json = cli.args.@"create-options" orelse "{}";
    const create_opts = try std.json.parseFromSlice(zml.Platform.CreateOptions, allocator, create_opts_json, .{});
    const platform = context.autoPlatform(create_opts.value).withCompilationOptions(compilation_options);
    create_opts.deinit();
    context.printAvailablePlatforms(platform);

    var store = try zml.aio.detectFormatAndOpen(allocator, model_weights_path);
    defer store.deinit();

    // Initialize model
    const seq_len: u32 = cli.args.@"seq-len" orelse 512;
    const qwen_options: qwen.Qwen.Options = .{
        .max_seq_len = seq_len,
        .sampling_strategy = .{
            .topk = 1,
            .temperature = 1.0,
        },
    };

    var compiler_arena = std.heap.ArenaAllocator.init(allocator);
    defer compiler_arena.deinit();

    const qwen_tensors: qwen.Qwen3VL = try qwen.Qwen3VL.init(compiler_arena.allocator(), config, qwen_options, store);

    // Load tokenizer early (needed for preprocessor)
    var tokenizer = blk: {
        log.info("Loading tokenizer from {s}", .{model_tokenizer_path});
        var timer = try stdx.time.Timer.start();
        defer log.info("Loaded tokenizer from {s} [{D}]", .{ model_tokenizer_path, timer.read() });

        break :blk try zml.tokenizer.Tokenizer.fromFile(allocator, model_tokenizer_path);
    };
    errdefer tokenizer.deinit();

    const prompt = cli.args.prompt orelse "Describe this image.";

    // Use preprocessor to calculate all needed values for compilation
    const preprocessor_input = try preprocessor(
        allocator,
        tokenizer,
        prompt,
        config,
        preprocessor_config,
        image_path,
        seq_len,
        1024, // max_side
    );
    defer {
        preprocessor_input.image_buffer_chw.deinit(allocator);
        preprocessor_input.prompt_tokens.deinit(allocator);
        preprocessor_input.prompt_shape.deinit(allocator);
        preprocessor_input.image_dim.deinit(allocator);
        preprocessor_input.token_index.deinit(allocator);
    }

    // Use shapes from preprocessor for compilation
    const image_buffer_shape = preprocessor_input.image_buffer_chw.shape();
    const prompt_tokens_shape = preprocessor_input.prompt_tokens.shape();
    const prompt_shape_shape = preprocessor_input.prompt_shape.shape();
    const image_dim_shape = preprocessor_input.image_dim.shape();
    const token_index_shape = preprocessor_input.token_index.shape();
    const pixel_value_mock_shape = zml.Shape.init(.{ .a = 1, .b = 1 }, .f32);

    // Specify shapes for decode
    const decode_input_ids_shape = zml.Shape.init(.{ .bs = 1, .seq = 1 }, .u32);
    const decode_cache_position_shape = zml.Shape.init(.{}, .i64);
    const decode_mrope_shape = zml.Shape.init(.{ .seq = 1 }, .i32);

    const dtype = qwen_tensors.qwen.text_model.embed_tokens.weight.dtype();
    const kv_shape = zml.Shape.init(.{
        .layer = config.text_config.num_hidden_layers,
        .k = seq_len,
        .h = config.text_config.num_key_value_heads,
        .hd = config.text_config.head_dim,
    }, dtype).withSharding(.{.h});
    const kv_cache_shape: zml.ShapeOf(qwen.KvCache) = qwen.KvCache.initShape(kv_shape);

    // Compile models asynchronously
    var start = try std.time.Timer.start();
    var fut_mod_prefill = try async.async(zml.compileModel, .{
        allocator,
        qwen.Qwen3VL.forward,
        qwen_tensors,
        .{
            image_buffer_shape,
            prompt_tokens_shape,
            image_dim_shape,
            token_index_shape,
            prompt_shape_shape,
            kv_cache_shape,
            preprocessor_input.h_resized,
            preprocessor_input.w_resized,
            pixel_value_mock_shape,
        },
        platform,
    });

    var fut_mod_decode = try async.async(zml.compileModel, .{
        allocator,
        qwen.Qwen3VL.forward_decode,
        qwen_tensors,
        .{
            decode_input_ids_shape,
            decode_cache_position_shape,
            kv_cache_shape,
            decode_mrope_shape,
        },
        platform,
    });

    // Load weights while compiling
    log.info("\tLoading Qwen3-VL weights from {s}...", .{model_weights_path});
    var qwen_buffers = try store.loadModelById(qwen.Qwen3VL, compiler_arena.allocator(), qwen_tensors, platform);
    defer zml.aio.unloadBuffers(&qwen_buffers);
    log.info("✅\tLoaded weights in {D}", .{start.read()});

    var qwen_module_prefill = (try fut_mod_prefill.await()).prepare(qwen_buffers);
    defer qwen_module_prefill.deinit();
    var qwen_module_decode = (try fut_mod_decode.await()).prepare(qwen_buffers);
    defer qwen_module_decode.deinit();
    log.info("✅\tCompiled model in {D}", .{start.read()});

    log.info("Creating KvCache", .{});
    const kv_cache = try qwen.KvCache.initBuffer(kv_shape, platform);

    log.info("✅\tPrompt: {s}", .{prompt});
    log.info("✅\tImage: {s}", .{image_path});

    var stdout = std.fs.File.stdout().writer(&.{});

    try generateText(
        config,
        qwen_tensors,
        qwen_module_prefill,
        qwen_module_decode,
        kv_cache,
        tokenizer,
        allocator,
        prompt[0..],
        image_path[0..],
        preprocessor_config,
        512,
        &stdout.interface,
    );
}

fn bool_parser(in: []const u8) error{}!bool {
    return std.mem.indexOfScalar(u8, "tTyY1", in[0]) != null;
}

// Keep all existing helper functions unchanged
pub const Size = struct {
    longest_edge: f64,
    shortest_edge: f64,
};

pub const PreprocessorConfig = struct {
    size: Size,
    patch_size: u32,
    temporal_patch_size: u32,
    image_mean: []const f32,
    image_std: []const f32,
};

pub fn preprocessor(allocator: std.mem.Allocator, tokenizer: zml.tokenizer.Tokenizer, prompt: []const u8, config: qwen.Qwen.Config, preprocessor_config: PreprocessorConfig, image_path: []const u8, max_seq_len: u32, max_side: u32) !struct { image_buffer_chw: zml.HostBuffer, prompt_tokens: zml.HostBuffer, prompt_shape: zml.HostBuffer, image_dim: zml.HostBuffer, token_index: zml.HostBuffer, h_resized: u32, w_resized: u32 } {
    var image_rgb = try loadBmpAsRgb(allocator, image_path);
    defer image_rgb.deinit(allocator);
    const image_hwc = image_rgb.data;

    // Allouer le buffer de destination (max_side x max_side x 3)
    const image_buffer = try allocator.alloc(u8, max_side * max_side * 3);
    // Initialiser à zéro (padding)
    @memset(image_buffer, 0);

    // Créer le HostBuffer pour l'image réelle (petite)
    const image_small_hwc = zml.HostBuffer.fromSlice(zml.Shape.init(.{ .h = image_rgb.height, .w = image_rgb.width, .c = 3 }, .u8), image_hwc);

    // Créer le HostBuffer pour le buffer de destination (grand)
    const image_buffer_hwc = zml.HostBuffer.fromSlice(zml.Shape.init(.{ .h = max_side, .w = max_side, .c = 3 }, .u8), image_buffer);

    // Insérer l'image réelle dans le coin supérieur gauche du grand buffer
    // Puisque le buffer de destination est contigu, on peut copier ligne par ligne
    const small_height = @as(usize, @intCast(image_rgb.height));
    const small_width = @as(usize, @intCast(image_rgb.width));
    const channels = 3;
    const row_size_small = small_width * channels;
    const row_size_large = @as(usize, @intCast(max_side)) * channels;

    // Copier ligne par ligne
    const small_bytes = image_small_hwc.bytes();
    var large_bytes = image_buffer_hwc.mutBytes();

    for (0..small_height) |h| {
        const src_offset = h * row_size_small;
        const dst_offset = h * row_size_large;
        @memcpy(large_bytes[dst_offset .. dst_offset + row_size_small], small_bytes[src_offset .. src_offset + row_size_small]);
    }
    //const image_buffer_chw = try image_buffer_hwc.reshape(.{ .c = 3, .h = image_rgb.height, .w = image_rgb.width });

    //create host buffers
    const image_size: [3]i32 = .{ @intCast(image_rgb.height), @intCast(image_rgb.width), 3 };
    for (image_size) |size| {
        log.info("image_size: {d}", .{size});
    }

    //compute h and w resized
    const height = image_rgb.height;
    const width = image_rgb.width;
    log.info("height: {d}", .{height});
    log.info("width: {d}", .{width});
    const factor = preprocessor_config.patch_size * preprocessor_config.temporal_patch_size;
    const min_pixels = preprocessor_config.size.shortest_edge;
    const max_pixels = preprocessor_config.size.longest_edge;
    stdx.debug.assert(@max(height, width) / @min(height, width) <= 200, "Invalid image size", .{});
    var h_resized = @round(@as(f64, @floatFromInt(height)) / @as(f64, @floatFromInt(factor))) * @as(f64, @floatFromInt(factor));
    var w_resized = @round(@as(f64, @floatFromInt(width)) / @as(f64, @floatFromInt(factor))) * @as(f64, @floatFromInt(factor));
    log.info("h_resized: {d}", .{@as(u32, @intFromFloat(h_resized))});
    log.info("w_resized: {d}", .{@as(u32, @intFromFloat(w_resized))});
    if (h_resized * w_resized > max_pixels) {
        const beta = std.math.sqrt(@as(f64, @floatFromInt(height * width)) / max_pixels);
        h_resized = @max(@as(f64, @floatFromInt(factor)), std.math.floor(@as(f64, @floatFromInt(height)) / beta / @as(f64, @floatFromInt(factor))) * @as(f64, @floatFromInt(factor)));
        w_resized = @max(@as(f64, @floatFromInt(factor)), std.math.floor(@as(f64, @floatFromInt(width)) / beta / @as(f64, @floatFromInt(factor))) * @as(f64, @floatFromInt(factor)));
        log.info("h_resized first if: {d}", .{@as(u32, @intFromFloat(h_resized))});
        log.info("w_resized first if: {d}", .{@as(u32, @intFromFloat(w_resized))});
    } else if (h_resized * w_resized < min_pixels) {
        const beta = std.math.sqrt(min_pixels) / @as(f64, @floatFromInt(height * width));
        h_resized = @max(@as(f64, @floatFromInt(factor)), std.math.ceil(@as(f64, @floatFromInt(height)) * beta / @as(f64, @floatFromInt(factor))) * @as(f64, @floatFromInt(factor)));
        w_resized = @max(@as(f64, @floatFromInt(factor)), std.math.ceil(@as(f64, @floatFromInt(width)) * beta / @as(f64, @floatFromInt(factor))) * @as(f64, @floatFromInt(factor)));
        log.info("h_resized second if: {d}", .{@as(u32, @intFromFloat(h_resized))});
        log.info("w_resized second if: {d}", .{@as(u32, @intFromFloat(w_resized))});
    }
    log.info("h_resized: {d}", .{@as(u32, @intFromFloat(h_resized))});
    log.info("w_resized: {d}", .{@as(u32, @intFromFloat(w_resized))});
    const patch_size = config.vision_config.patch_size;

    const number_image_pad_tokens = 1 * (@as(u32, @intFromFloat(h_resized)) / patch_size) * (@as(u32, @intFromFloat(w_resized)) / patch_size) / std.math.pow(u32, config.vision_config.spatial_merge_size, 2);
    log.info("number_image_pad_tokens: {d}", .{number_image_pad_tokens});
    const result = try applyChatTemplate(allocator, tokenizer, prompt, number_image_pad_tokens);
    const prompt_encoded = result.prompt_tokens;
    const prompt_shape = result.prompt_shape;
    var decoder = try tokenizer.decoder();
    defer decoder.deinit();
    const prompt_text = try decoder.decode(prompt_encoded);
    log.info("prompt_text: {s}", .{prompt_text});
    for (prompt_encoded) |token| {
        log.info("token: {d}", .{token});
    }
    defer allocator.free(prompt_encoded);
    const prompt_buffer = try allocator.alloc(u32, max_seq_len);
    @memcpy(prompt_buffer[0..prompt_encoded.len], prompt_encoded);
    const prompt_tokens = zml.HostBuffer.fromSlice(zml.Shape.init(.{ .bs = 1, .seq = max_seq_len }, .u32), prompt_buffer);

    const prompt_shape_buffer = try zml.HostBuffer.empty(allocator, zml.Shape.init(.{ .chw = 3 }, .i32));
    @memcpy(prompt_shape_buffer.mutItems(i32), &prompt_shape);

    // Créer des HostBuffer qui possèdent leur mémoire
    const image_size_buffer = try zml.HostBuffer.empty(allocator, zml.Shape.init(.{ .chw = 3 }, .i32));
    @memcpy(image_size_buffer.mutItems(i32), &image_size);
    log.info("image_size_buffer values: {d}, {d}, {d}", .{ image_size_buffer.items(i32)[0], image_size_buffer.items(i32)[1], image_size_buffer.items(i32)[2] });

    const token_index_buffer = try zml.HostBuffer.empty(allocator, zml.Shape.init(.{1}, .i64));
    const index: [1]i64 = .{0};
    @memcpy(token_index_buffer.mutItems(i64), &index);

    return .{ .image_buffer_chw = image_buffer_hwc, .prompt_tokens = prompt_tokens, .prompt_shape = prompt_shape_buffer, .image_dim = image_size_buffer, .token_index = token_index_buffer, .h_resized = @as(u32, @intFromFloat(h_resized)), .w_resized = @as(u32, @intFromFloat(w_resized)) };
}

pub fn applyChatTemplate(allocator: std.mem.Allocator, tokenizer: zml.tokenizer.Tokenizer, prompt: []const u8, number_image_pad_tokens: u32) !struct { prompt_tokens: []const u32, prompt_shape: [3]i32 } {
    var encoder = try tokenizer.encoder();
    defer encoder.deinit();
    const im_start_id = tokenizer.tokenToId("<|im_start|>") orelse return error.NoSuchToken;
    const im_end_id = tokenizer.tokenToId("<|im_end|>") orelse return error.NoSuchToken;
    const user = tokenizer.tokenToId("user") orelse return error.NoSuchToken;
    const assistant = tokenizer.tokenToId("assistant") orelse return error.NoSuchToken;
    const vision_start_id = tokenizer.tokenToId("<|vision_start|>") orelse return error.NoSuchToken;
    const vision_end_id = tokenizer.tokenToId("<|vision_end|>") orelse return error.NoSuchToken;
    const image_pad_id = tokenizer.tokenToId("<|image_pad|>") orelse return error.NoSuchToken;
    const newline = (try encoder.encode("\n"))[0];

    var tokens: std.ArrayList(u32) = try .initCapacity(allocator, prompt.len);
    try tokens.appendSlice(allocator, &.{ im_start_id, user, newline });
    try tokens.appendSlice(allocator, &.{vision_start_id});
    for (0..number_image_pad_tokens) |i| {
        _ = i; // autofix
        try tokens.appendSlice(allocator, &.{image_pad_id});
    }
    try tokens.appendSlice(allocator, &.{vision_end_id});
    try tokens.appendSlice(allocator, try encoder.encode(prompt));
    try tokens.appendSlice(allocator, &.{ im_end_id, newline });
    try tokens.appendSlice(allocator, &.{ im_start_id, assistant, newline });
    log.info("tokens: {d}", .{tokens.items.len});
    const prompt_tokens = try encoder.encode(prompt);
    log.info("prompt length: {d}", .{prompt_tokens.len});
    const prompt_shape: [3]i32 = .{ 4, @as(i32, @intCast(number_image_pad_tokens)), @as(i32, @intCast(prompt_tokens.len)) + 6 };
    return .{ .prompt_tokens = try tokens.toOwnedSlice(allocator), .prompt_shape = prompt_shape };
}

pub const RgbImage = struct {
    width: u32,
    height: u32,
    data: []u8,

    pub fn deinit(self: *RgbImage, allocator: std.mem.Allocator) void {
        allocator.free(self.data);
        self.* = undefined;
    }
};

pub fn loadBmpAsRgb(allocator: std.mem.Allocator, path: []const u8) !RgbImage {
    var file = try std.fs.cwd().openFile(path, .{ .mode = .read_only });
    defer file.close();

    const max_len = 64 * 1024 * 1024; // 64 MiB safety cap
    const file_bytes = try file.readToEndAlloc(allocator, max_len);
    defer allocator.free(file_bytes);

    if (file_bytes.len < 54) return error.InvalidBmpHeader;
    if (!std.mem.eql(u8, file_bytes[0..2], "BM")) return error.InvalidBmpSignature;

    const readU16 = struct {
        fn f(bytes: []const u8) u16 {
            return std.mem.readInt(u16, bytes[0..2], .little);
        }
    }.f;
    const readI32 = struct {
        fn f(bytes: []const u8) i32 {
            return std.mem.readInt(i32, bytes[0..4], .little);
        }
    }.f;
    const readU32 = struct {
        fn f(bytes: []const u8) u32 {
            return std.mem.readInt(u32, bytes[0..4], .little);
        }
    }.f;

    const data_offset = readU32(file_bytes[10..14]);
    const dib_header_size = readU32(file_bytes[14..18]);
    if (dib_header_size < 40) return error.UnsupportedBmpFormat;

    const width_i32 = readI32(file_bytes[18..22]);
    const height_i32 = readI32(file_bytes[22..26]);
    if (width_i32 <= 0 or height_i32 == 0) return error.InvalidBmpDimensions;

    const planes = readU16(file_bytes[26..28]);
    const bits_per_pixel = readU16(file_bytes[28..30]);
    const compression = readU32(file_bytes[30..34]);
    if (planes != 1 or compression != 0 or bits_per_pixel != 24) return error.UnsupportedBmpFormat;

    const width: u32 = @intCast(width_i32);
    const abs_height: u32 = @intCast(if (height_i32 < 0) -height_i32 else height_i32);
    const is_top_down = height_i32 < 0;

    const row_stride = ((width * 3 + 3) / 4) * 4;
    const pixel_array_size = row_stride * abs_height;
    if (data_offset + pixel_array_size > file_bytes.len) return error.TruncatedBmp;

    const rgb_len = width * abs_height * 3;
    var rgb_data = try allocator.alloc(u8, rgb_len);
    errdefer allocator.free(rgb_data);

    var row: u32 = 0;
    while (row < abs_height) : (row += 1) {
        const src_row_index = if (is_top_down) row else abs_height - 1 - row;
        const src_start = data_offset + src_row_index * row_stride;
        const src_slice = file_bytes[src_start .. src_start + row_stride];

        const dst_start = row * width * 3;
        var col: u32 = 0;
        while (col < width) : (col += 1) {
            const src_pixel = col * 3;
            const dst_pixel = dst_start + col * 3;
            // BMP pixels are stored in BGR order.
            rgb_data[dst_pixel + 0] = src_slice[src_pixel + 2];
            rgb_data[dst_pixel + 1] = src_slice[src_pixel + 1];
            rgb_data[dst_pixel + 2] = src_slice[src_pixel + 0];
        }
    }
    log.info("width: {d}", .{width});
    log.info("abs_height: {d}", .{abs_height});

    return RgbImage{
        .width = width,
        .height = abs_height,
        .data = rgb_data,
    };
}

// Unused functions kept for compatibility with old activations-based workflow
const ConvertError = error{
    UnsupportedFloatType,
};

fn ensureStoreFloat32(store: *zml.aio.BufferStore) !void {
    var it = store.buffers.iterator();
    const allocator = store.arena.allocator();
    while (it.next()) |entry| {
        const dtype = entry.value_ptr.shape().dtype();
        if (!dtype.isFloat() or dtype == .f32) continue;
        entry.value_ptr.* = try hostBufferToF32(allocator, entry.value_ptr.*);
    }
}

fn hostBufferToF32(allocator: std.mem.Allocator, src: zml.HostBuffer) !zml.HostBuffer {
    const dtype = src.shape().dtype();
    if (!dtype.isFloat() or dtype == .f32) return src;

    const dst_shape = src.shape().withDtype(.f32);
    const element_count = @as(usize, @intCast(dst_shape.count()));
    const data = try allocator.alloc(f32, element_count);
    const out = data;

    switch (dtype) {
        .bf16 => {
            const values = src.items(floats.BFloat16);
            for (values, 0..) |value, idx| {
                out[idx] = floats.BFloat16.toF32(value);
            }
        },
        .f16 => {
            const values = src.items(f16);
            for (values, 0..) |value, idx| {
                out[idx] = @as(f32, @floatCast(value));
            }
        },
        .f64 => {
            const values = src.items(f64);
            for (values, 0..) |value, idx| {
                out[idx] = @as(f32, @floatCast(value));
            }
        },
        else => return ConvertError.UnsupportedFloatType,
    }

    return zml.HostBuffer.fromBytes(dst_shape, std.mem.sliceAsBytes(out));
}

pub fn testFinalOutput(
    platform: zml.Platform,
    model: anytype,
    model_weights: zml.Bufferized(@TypeOf(model)),
    tokenizer: zml.tokenizer.Tokenizer,
    writer: *std.Io.Writer,
    preprocessor_config: PreprocessorConfig,
    pixel_values_host: zml.HostBuffer,
) !zml.Buffer {
    _ = writer; // autofix
    var arena = std.heap.ArenaAllocator.init(std.heap.c_allocator);
    defer arena.deinit();
    const alloc = arena.allocator();
    const fwd = @TypeOf(model).forward;

    var tokenizer_decoder = try tokenizer.decoder();
    defer tokenizer_decoder.deinit();

    const preprocessor_input = try preprocessor(alloc, tokenizer, "Describe this image.", model.qwen.config, preprocessor_config, "/Users/louislechevalier/Downloads/snail.bmp", 512, 1024);
    const image_buffer_chw = preprocessor_input.image_buffer_chw;
    const prompt_tokens = preprocessor_input.prompt_tokens;
    const prompt_shape = preprocessor_input.prompt_shape;
    const image_dim = preprocessor_input.image_dim;
    defer image_dim.deinit(alloc);
    log.info("image_dim values before toDevice: {d}, {d}, {d}", .{ image_dim.items(i32)[0], image_dim.items(i32)[1], image_dim.items(i32)[2] });
    const token_index = preprocessor_input.token_index;
    defer token_index.deinit(alloc);
    const h_resized = preprocessor_input.h_resized;
    const w_resized = preprocessor_input.w_resized;

    const kv_shape = zml.Shape.init(.{
        .layer = model.qwen.config.text_config.num_hidden_layers,
        .k = 512,
        .h = model.qwen.config.text_config.num_key_value_heads,
        .hd = model.qwen.config.text_config.head_dim,
    }, .f32);
    const kv_cache_shape: zml.ShapeOf(qwen.KvCache) = qwen.KvCache.initShape(kv_shape);

    const exe = try zml.compileModel(alloc, fwd, model, .{ image_buffer_chw.shape(), prompt_tokens.shape(), image_dim.shape(), token_index.shape(), prompt_shape.shape(), kv_cache_shape, h_resized, w_resized, pixel_values_host.shape() }, platform);
    const mod = exe.prepare(model_weights);
    const image_buf = try image_buffer_chw.toDevice(platform);
    defer image_buf.deinit();
    const prompt_buf = try prompt_tokens.toDevice(platform);
    defer prompt_buf.deinit();
    const prompt_shape_buf = try prompt_shape.toDevice(platform);
    defer prompt_shape_buf.deinit();
    const image_dim_buf = try image_dim.toDevice(platform);
    defer image_dim_buf.deinit();
    const token_index_buf = try token_index.toDevice(platform);
    defer token_index_buf.deinit();
    const kv_cache_buf = try qwen.KvCache.initBuffer(kv_shape, platform);
    const pixel_values_buf = try pixel_values_host.toDevice(platform);
    defer pixel_values_buf.deinit();
    const output_tuple = mod.call(.{ image_buf, prompt_buf, image_dim_buf, token_index_buf, prompt_shape_buf, kv_cache_buf, h_resized, w_resized, pixel_values_buf });
    const output_buf = output_tuple[0];
    return output_buf;
}

fn testImplementation(
    platform: zml.Platform,
    qwen_model: qwen.Qwen3VL,
    qwen_weights: zml.Bufferized(qwen.Qwen3VL),
    activations: zml.aio.BufferStore,
) !void {
    _ = platform;
    _ = qwen_model;
    _ = qwen_weights;
    _ = activations;
    // Unused function kept for compatibility
    // try zml.testing.testLayer(platform, activations, "model", qwen_model, qwen_weights, 5e-2);
}

fn setupKvCacheFromActivations(activation_buffer_store: *zml.aio.BufferStore, config: qwen.Qwen.Config) !void {
    const num_layers = config.text_config.num_hidden_layers;
    const num_kv_heads = config.text_config.num_key_value_heads;
    const max_seq_len = 3000;
    const head_dim = config.text_config.head_dim;

    const kv_shape = zml.Shape.init(.{
        @as(i64, num_layers),
        @as(i64, max_seq_len),
        @as(i64, num_kv_heads),
        @as(i64, head_dim),
    }, .f32);

    var kv_k_buffer = try zml.HostBuffer.empty(activation_buffer_store.arena.allocator(), kv_shape);
    var kv_v_buffer = try zml.HostBuffer.empty(activation_buffer_store.arena.allocator(), kv_shape);

    {
        const k_items = kv_k_buffer.mutItems(f32);
        @memset(k_items, 0);

        const v_items = kv_v_buffer.mutItems(f32);
        @memset(v_items, 0);
    }

    try activation_buffer_store.buffers.put(activation_buffer_store.arena.allocator(), "model.in.5", kv_k_buffer);
    try activation_buffer_store.buffers.put(activation_buffer_store.arena.allocator(), "model.in.6", kv_v_buffer);

    const layer_index_shape = zml.Shape.init(.{}, .u32);
    var layer_index_data: [1]u32 = .{0};
    const layer_index_buffer = zml.HostBuffer.fromSlice(layer_index_shape, &layer_index_data);

    try activation_buffer_store.buffers.put(activation_buffer_store.arena.allocator(), "model.in.7", layer_index_buffer);
}
